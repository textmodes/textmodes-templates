title: Technical details of our setup
published: 2015-01-29
author: maze

So how do we actually serve out tons of images rendered from artpacks and
make the contents searchable? Luckily there some very good open source tools
out there to make life more easy. Yep, that's right,
[TEXTMOD.ES](http://textmod.es/) is entirely built on open source technology.
Not only because it's a good economical choice, but it also allows the authors
to contribute back to the open source community and build a better world in
doing so.


### The core: Python

Python is gaining in popularity, and there are some great (micro) web
frameworks that allow for rapid development. We have chosen to build our site
on top of the [Flask](http://flask.pocoo.org/) web framework, which comes with
[Werkzeug](http://werkzeug.pocoo.org/) to interact with our webserver over the
[WSGI](http://wsgi.readthedocs.org/en/latest/) protocol. Our templates are
renedered with [Jinja 2](http://jinja.pocoo.org/), simply because it's a very
nice templating language and people coming from
[Django](http://www.djangoproject.com/) should be acustomed to most of its
filter and function syntaxis.


### Storing data: PostgreSQL and Elasticsearch

Our main data engine is a relational database, namely
[PostgreSQL](http://www.postgresql.org/). PostgreSQL is fully
[ACID](https://en.wikipedia.org/wiki/ACID) compliant and has support for a
wide variety of native data types. While PostgreSQL also has full text search
capabilities, [Elasticsearch](http://www.elasticsearch.org/) makes full text
searches a lot more easy and a lot faster because it's entirely optimized for
that purpose. The search index is kept in sync using
[SQLAlchemy](http://www.sqlalchemy.org/) signals and periodic cron jobs.


### Serving data: haproxy, nginx and uwsgi

[TEXTMOD.ES](http://textmod.es/) consists of a multi tiered, clustered set of
web servers, each with its own purpose. The main entry point for clients is
[haproxy](http://www.haproxy.org/), a high performance TCP/HTTP load balancer.

The haproxy load balancer devides client requests across the stack of
[nginx](http://nginx.org/) web servers. The nginx instances are set up to
serve both static and dynamic content. The caching tier uses a simple disk
based cache to serve static content. Dynamic content is passed on to the pool
of [uwsgi](https://uwsgi-docs.readthedocs.org/) workers which do the heavy
lifting of parsing the HTTP request and making it ready for
[Werkzeug](http://werkzeug.pocoo.org/) to chew on.

The nginx configuration for the dynamic content server looks like:

    :::nginx
    # This is where uwsgi is listening for incoming requests
    upstream worker {
        server unix:/tmp/worker.sock;
    }

    # Server definition for textmod.es
    server {
        listen 80;
        server_name *.textmod.es;
    
        # This is where we cache static content
        root /var/run/textmodes/cache;

        location / {
            # First we try to see if the requested URI exists on disk (in the
            # cache), if not, we pass it to the wsgi worker.
            try_files $uri @wsgi;
        }

        location @wsgi {
            internal;
            include uwsgi_params;
            uwsgi_pass worker;
        }
    }

As you may have noticed, there are a couple of sub domains that serve static
content for [TEXTMOD.ES](http://textmod.es/). We balance static resources over
the pool of proxies using a
[consistent hash ring](https://en.wikipedia.org/wiki/Consistent_hashing), to
allow browsers to better pipeline the loading of multiple static resources on
a single page, while still making optimal use of the browser cache by returning
the same URL for the same resource. These assets are also served by nginx in
reverse proxy mode with caching enabled. An excerpt from that configuration:

    :::nginx
    proxy_cache_path /var/run/textmodes/cache
        levels=1:2
        keys_zone=textmode:10m
        loader_threshold=300
        loader_files=200
        max_size=200m;

    upstream textmode-pc {
        server pc.textmod.es;
    }

    server {
        listen 80;
        server_name pc.xx-a.textmod.es pc.xx-b.textmod.es pc.xx-c.textmod.es;

        proxy_cache textmode;
        proxy_cache_valid 200 43200m;
        proxy_cache_valid 302 5m;
        proxy_cache_valid 404 1m;
        proxy_cache_valid 500 1s;
        proxy_cache_valid any 5m;
        proxy_connect_timeout 5s;
        proxy_read_timeout 10s;

        # Error handlers
        error_page 502 @sorry;
        error_page 503 @sorry;
        error_page 504 @sorry_other;

        # Our default sorry handler, returns a blank PNG for images and a
        # sorry page for other requests.
        location @sorry {
            rewrite ^(.*)\.png$ /local/sorry.png last;
            rewrite ^(.*)$ /local/sorry.html last;
        }

        # Our other sorry handler, returns a redirect to a sibling proxy if
        # it's the first in the chain, otherwise, it will redirect (interna)
        # to the default sorry handler.
        location @sorry_other {
            if ($request_uri !~ sorry= ) {
                rewrite ^(.*)$ http://pc.yy-c.textmod.es$request_uri&sorry=xx;
            }
            rewrite ^(.*)$ @sorry last;
        }
   
        # Our local content
        location /local {
            alias /var/www/local;
        }

        # All requests under this URI are proxied and cached.
        location /path/to/cache {
            proxy_pass http://textmode-pc;
        }

        # All other requests are redirected back to the main project page.
        location ~ ^.* {
            rewrite ^ http://pc.textmod.es$request_uri permanent;
        }
    }
